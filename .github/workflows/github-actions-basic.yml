name: Build and test

on:
  push:
    branches:
    - '**'
    - '!branch-*.*'

jobs:
  # Build: build and run the tests for specified modules.
  build:
    # Ubuntu 22.04 is the latest LTS.
    runs-on: ubuntu-22.04
    strategy:
      fail-fast: false
    env:
      SPARK_VERSION: ${{ matrix.spark }}
    steps:
    - name: sbt
      run: |
        sudo apt-get update
        sudo apt-get install -y apt-transport-https curl gnupg -yqq
        echo "deb https://repo.scala-sbt.org/scalasbt/debian all main" | sudo tee /etc/apt/sources.list.d/sbt.list
        echo "deb https://repo.scala-sbt.org/scalasbt/debian /" | sudo tee /etc/apt/sources.list.d/sbt_old.list
        curl -sL "https://keyserver.ubuntu.com/pks/lookup?op=get&search=0x2EE0EA64E40A89B84B2DF73499E82A75642AC823" | sudo -H gpg --no-default-keyring --keyring gnupg-ring:/etc/apt/trusted.gpg.d/scalasbt-release.gpg --import
        sudo chmod 644 /etc/apt/trusted.gpg.d/scalasbt-release.gpg
        sudo apt-get update
        sudo apt-get install -y sbt
    - name: Checkout
      uses: actions/checkout@v2
      # In order to fetch changed files
      with:
        fetch-depth: 0
        repository: holdenk/spark-upgrade
        ref: main
    - name: Sync the current branch with the latest in spark-testing-base
      if: github.repository != 'holdenk/spark-upgrade'
      id: sync-branch
      run: |
        apache_spark_ref=`git rev-parse HEAD`
        git fetch https://github.com/$GITHUB_REPOSITORY.git ${GITHUB_REF##*/}
        git -c user.name='Spark Test Account' -c user.email='sparktestacc@gmail.com' merge --no-commit --progress --squash FETCH_HEAD
        git -c user.name='Spark Test Account' -c user.email='sparktestacc@gmail.com' commit -m "Merged commit"
        echo "::set-output name=SPARK_REF::$apache_spark_ref"
    # Install python deps
    - name: Install python deps
      run: pip install -r python/requirements.txt
    # Run the scala tests.
    - name: Run sbt tests on scalafix
      run: cd scalafix; sbt ";clean;compile;test"
    - name: Run sbt tests on our WAP plugin
      run: cd iceberg-spark-upgrade-wap-plugin; sbt ";clean;test"
    # Run Python style checks
    - name: Run Python style
      run: flake8 --max-line-length 100 --ignore=E129,W504 --exclude  sample_inputs .
    # Run the sql tests
    - name: Run Python style
      run: cd sql; pip install -e .; pytest .
